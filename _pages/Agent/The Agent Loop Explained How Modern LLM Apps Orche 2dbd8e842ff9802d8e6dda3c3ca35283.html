---
layout: archive
permalink: /agent-loop/
title: "Agent"
author_profile: false
---

<style>
/* cspell:disable-file */
/* webkit printing magic: print all background colors */
.agent-loop-notion {
	-webkit-print-color-adjust: exact;
	print-color-adjust: exact;
}
.agent-loop-notion * {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
	print-color-adjust: exact;
}

.agent-loop-notion, .agent-loop-notion {
	margin: 0;
	padding: 0;
}
@media only screen {
	.agent-loop-notion {
		margin: 0;
		max-width: 100%;
		width: 100%;
		color: rgb(55, 53, 47);
	}
}

.agent-loop-notion {
	line-height: 1.5;
	white-space: pre-wrap;
}

/* --- GitHub Pages UI overrides (minimal surgery) --- */
/* Standalone page layout: center the content column and hide the redundant theme title ("Agent"). */
#main > .archive {
	float: none !important;
	width: 100% !important;
	/* Karpathy-style: keep a readable column width while still feeling "wide". */
	max-width: clamp(740px, 80vw, 900px) !important;
	margin-left: auto !important;
	margin-right: auto !important;
}
#main > .archive > .page__title {
	display: none !important;
}

/* Make the article use the available width in the theme content column */
.agent-loop-notion {
	max-width: 100% !important;
}

/* Let the Notion-exported <article class="page"> fill the theme content column.
   Notion adds large side padding which makes the page feel too narrow. */
.agent-loop-notion article.page {
	width: 100% !important;
	max-width: clamp(740px, 80vw, 900px) !important;
	margin-left: auto !important;
	margin-right: auto !important;
	padding-left: 0 !important;
	padding-right: 0 !important;
}

/* Callout layout (match Notion: icon left, text right) */
.agent-loop-notion figure.callout {
	flex-wrap: nowrap !important;
	gap: 0.75rem;
}
.agent-loop-notion figure.callout > div:first-child {
	flex: 0 0 auto;
	line-height: 1;
}
.agent-loop-notion figure.callout > div:last-child {
	width: auto !important;
	flex: 1 1 auto;
	min-width: 0;
}

/* Fix code wrapping (avoid mid-word breaks). Use horizontal scroll instead. */
.agent-loop-notion pre,
.agent-loop-notion pre code,
.agent-loop-notion pre code[class*="language-"],
.agent-loop-notion code[class*="language-"] {
	white-space: pre !important;
	word-break: normal !important;
	overflow-wrap: normal !important;
}
.agent-loop-notion pre {
	overflow-x: auto !important;
}

/* Code block copy button (similar UX to DeepLearning-Julia page) */
.agent-loop-notion pre {
	position: relative;
}
.agent-loop-notion .agent-loop-copy-btn {
	position: absolute;
	top: 0.5rem;
	right: 0.5rem;
	z-index: 2;
	font-size: 0.75rem;
	line-height: 1;
	padding: 0.35rem 0.5rem;
	border-radius: 6px;
	border: 1px solid rgba(0, 0, 0, 0.18);
	background: rgba(255, 255, 255, 0.85);
	color: #222;
	cursor: pointer;
	-webkit-backdrop-filter: blur(6px);
	backdrop-filter: blur(6px);
}
.agent-loop-notion .agent-loop-copy-btn:hover {
	background: rgba(255, 255, 255, 0.98);
}
.agent-loop-notion .agent-loop-copy-btn:active {
	transform: translateY(1px);
}

.agent-loop-notion a, .agent-loop-notion a.visited {
	color: inherit;
	text-decoration: underline;
}

.agent-loop-notion .pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

.agent-loop-notion h1, .agent-loop-notion h2, .agent-loop-notion h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

/* Override strong tags inside headings to maintain consistent weight */
.agent-loop-notion h1 strong, .agent-loop-notion h2 strong, .agent-loop-notion h3 strong {
	font-weight: 600;
}

.agent-loop-notion .page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

.agent-loop-notion h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

.agent-loop-notion h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

.agent-loop-notion h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.agent-loop-notion .source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.agent-loop-notion .callout {
	border-radius: 10px;
	padding: 1rem;
}

.agent-loop-notion figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

.agent-loop-notion figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

.agent-loop-notion mark {
	background-color: transparent;
}

.agent-loop-notion .indented {
	padding-left: 1.5em;
}

.agent-loop-notion hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

.agent-loop-notion img {
	max-width: 100%;
}

@media only print {
	.agent-loop-notion img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.agent-loop-notion .collection-content {
	font-size: 0.875rem;
}

.agent-loop-notion .collection-content td {
	white-space: pre-wrap;
	word-break: break-word;
}

.agent-loop-notion .column-list {
	display: flex;
	justify-content: space-between;
}

.agent-loop-notion .column {
	padding: 0 1em;
}

.agent-loop-notion .column:first-child {
	padding-left: 0;
}

.agent-loop-notion .column:last-child {
	padding-right: 0;
}

.agent-loop-notion .table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.agent-loop-notion .table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.agent-loop-notion .table_of_contents-indent-2 {
	margin-left: 3rem;
}

.agent-loop-notion .table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.agent-loop-notion .table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

.agent-loop-notion table, .agent-loop-notion th, .agent-loop-notion td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

.agent-loop-notion table {
	border-left: none;
	border-right: none;
}

.agent-loop-notion th, .agent-loop-notion td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

.agent-loop-notion th {
	color: rgba(55, 53, 47, 0.6);
}

.agent-loop-notion ol, .agent-loop-notion ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

.agent-loop-notion li > ol:first-child, .agent-loop-notion li > ul:first-child {
	margin-block-start: 0.6em;
}

.agent-loop-notion ul > li {
	list-style: disc;
}

.agent-loop-notion ul.to-do-list {
	padding-inline-start: 0;
}

.agent-loop-notion ul.to-do-list > li {
	list-style: none;
}

.agent-loop-notion .to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

.agent-loop-notion ul.toggle > li {
	list-style: none;
}

.agent-loop-notion ul {
	padding-inline-start: 1.7em;
}

.agent-loop-notion ul > li {
	padding-left: 0.1em;
}

.agent-loop-notion ol {
	padding-inline-start: 1.6em;
}

.agent-loop-notion ol > li {
	padding-left: 0.2em;
}

.agent-loop-notion .mono ol {
	padding-inline-start: 2em;
}

.agent-loop-notion .mono ol > li {
	text-indent: -0.4em;
}

.agent-loop-notion .toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.agent-loop-notion .toggle > li > details {
	padding-left: 1.7em;
}

.agent-loop-notion .toggle > li > details > summary {
	margin-left: -1.1em;
}

.agent-loop-notion .selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.agent-loop-notion .collection-title {
	display: inline-block;
	margin-right: 1em;
}

.agent-loop-notion .page-description {
	margin-bottom: 2em;
}

.agent-loop-notion .simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.agent-loop-notion .simple-table td {
	height: 29px;
	min-width: 120px;
}

.agent-loop-notion .simple-table th {
	height: 29px;
	min-width: 120px;
}

.agent-loop-notion .simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.agent-loop-notion .simple-table-header {
	font-weight: 500;
}

.agent-loop-notion time {
	opacity: 0.5;
}

.agent-loop-notion .icon {
	display: inline-flex;
	align-items: center;
	justify-content: center;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

.agent-loop-notion img.icon {
	border-radius: 3px;
}

.agent-loop-notion .callout img.notion-static-icon {
	width: 1em;
	height: 1em;
}

.agent-loop-notion .callout p {
	margin: 0;
}

.agent-loop-notion .callout h1, .agent-loop-notion .callout h2, .agent-loop-notion .callout h3 {
	margin: 0 0 0.6rem;
}

.agent-loop-notion .user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.agent-loop-notion .user-icon-inner {
	font-size: 0.8em;
}

.agent-loop-notion .text-icon {
	border: 1px solid #000;
	text-align: center;
}

.agent-loop-notion .page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.agent-loop-notion .page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.agent-loop-notion .page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.agent-loop-notion .page-header-icon img {
	border-radius: 3px;
}

.agent-loop-notion .link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

.agent-loop-notion p > .user {
	opacity: 0.5;
}

.agent-loop-notion td > .user, .agent-loop-notion td > time {
	white-space: nowrap;
}

.agent-loop-notion input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

.agent-loop-notion p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.agent-loop-notion .image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.agent-loop-notion .code, .agent-loop-notion code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

.agent-loop-notion code {
	color: #eb5757;
}

.agent-loop-notion .code {
	padding: 1.5em 1em;
}

.agent-loop-notion .code-wrap {
	white-space: pre !important;
	word-break: normal !important;
	overflow-wrap: normal !important;
	overflow-x: auto;
}

.agent-loop-notion .code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

.agent-loop-notion blockquote {
	font-size: 1em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.agent-loop-notion blockquote.quote-large {
	font-size: 1.25em;
}

.agent-loop-notion .bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.agent-loop-notion .bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.agent-loop-notion .bookmark-text {
	display: flex;
	flex-direction: column;
}

.agent-loop-notion .bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.agent-loop-notion .bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.agent-loop-notion .bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.agent-loop-notion .bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.agent-loop-notion .sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.agent-loop-notion .code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.agent-loop-notion .serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.agent-loop-notion .mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.agent-loop-notion .pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.agent-loop-notion .pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.agent-loop-notion .pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.agent-loop-notion .pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.agent-loop-notion .pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.agent-loop-notion .pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.agent-loop-notion .pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.agent-loop-notion .pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.agent-loop-notion .pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.agent-loop-notion .pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.agent-loop-notion .pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.agent-loop-notion .pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.agent-loop-notion .pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.agent-loop-notion .pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.agent-loop-notion .pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.agent-loop-notion .pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.agent-loop-notion .highlight-default {
	color: rgba(44, 44, 43, 1);
}
.agent-loop-notion .highlight-gray {
	color: rgba(125, 122, 117, 1);
	fill: rgba(125, 122, 117, 1);
}
.agent-loop-notion .highlight-brown {
	color: rgba(159, 118, 90, 1);
	fill: rgba(159, 118, 90, 1);
}
.agent-loop-notion .highlight-orange {
	color: rgba(210, 123, 45, 1);
	fill: rgba(210, 123, 45, 1);
}
.agent-loop-notion .highlight-yellow {
	color: rgba(203, 148, 52, 1);
	fill: rgba(203, 148, 52, 1);
}
.agent-loop-notion .highlight-teal {
	color: rgba(80, 148, 110, 1);
	fill: rgba(80, 148, 110, 1);
}
.agent-loop-notion .highlight-blue {
	color: rgba(56, 125, 201, 1);
	fill: rgba(56, 125, 201, 1);
}
.agent-loop-notion .highlight-purple {
	color: rgba(154, 107, 180, 1);
	fill: rgba(154, 107, 180, 1);
}
.agent-loop-notion .highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.agent-loop-notion .highlight-red {
	color: rgba(207, 81, 72, 1);
	fill: rgba(207, 81, 72, 1);
}
.agent-loop-notion .highlight-default_background {
	color: rgba(44, 44, 43, 1);
}
.agent-loop-notion .highlight-gray_background {
	background: rgba(42, 28, 0, 0.07);
}
.agent-loop-notion .highlight-brown_background {
	background: rgba(139, 46, 0, 0.086);
}
.agent-loop-notion .highlight-orange_background {
	background: rgba(224, 101, 1, 0.129);
}
.agent-loop-notion .highlight-yellow_background {
	background: rgba(211, 168, 0, 0.137);
}
.agent-loop-notion .highlight-teal_background {
	background: rgba(0, 100, 45, 0.09);
}
.agent-loop-notion .highlight-blue_background {
	background: rgba(0, 124, 215, 0.094);
}
.agent-loop-notion .highlight-purple_background {
	background: rgba(102, 0, 178, 0.078);
}
.agent-loop-notion .highlight-pink_background {
	background: rgba(197, 0, 93, 0.086);
}
.agent-loop-notion .highlight-red_background {
	background: rgba(223, 22, 0, 0.094);
}
.agent-loop-notion .block-color-default {
	color: inherit;
	fill: inherit;
}
.agent-loop-notion .block-color-gray {
	color: rgba(125, 122, 117, 1);
	fill: rgba(125, 122, 117, 1);
}
.agent-loop-notion .block-color-brown {
	color: rgba(159, 118, 90, 1);
	fill: rgba(159, 118, 90, 1);
}
.agent-loop-notion .block-color-orange {
	color: rgba(210, 123, 45, 1);
	fill: rgba(210, 123, 45, 1);
}
.agent-loop-notion .block-color-yellow {
	color: rgba(203, 148, 52, 1);
	fill: rgba(203, 148, 52, 1);
}
.agent-loop-notion .block-color-teal {
	color: rgba(80, 148, 110, 1);
	fill: rgba(80, 148, 110, 1);
}
.agent-loop-notion .block-color-blue {
	color: rgba(56, 125, 201, 1);
	fill: rgba(56, 125, 201, 1);
}
.agent-loop-notion .block-color-purple {
	color: rgba(154, 107, 180, 1);
	fill: rgba(154, 107, 180, 1);
}
.agent-loop-notion .block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.agent-loop-notion .block-color-red {
	color: rgba(207, 81, 72, 1);
	fill: rgba(207, 81, 72, 1);
}
.agent-loop-notion .block-color-default_background {
	color: inherit;
	fill: inherit;
}
.agent-loop-notion .block-color-gray_background {
	background: rgba(240, 239, 237, 1);
}
.agent-loop-notion .block-color-brown_background {
	background: rgba(245, 237, 233, 1);
}
.agent-loop-notion .block-color-orange_background {
	background: rgba(251, 235, 222, 1);
}
.agent-loop-notion .block-color-yellow_background {
	background: rgba(249, 243, 220, 1);
}
.agent-loop-notion .block-color-teal_background {
	background: rgba(232, 241, 236, 1);
}
.agent-loop-notion .block-color-blue_background {
	background: rgba(229, 242, 252, 1);
}
.agent-loop-notion .block-color-purple_background {
	background: rgba(243, 235, 249, 1);
}
.agent-loop-notion .block-color-pink_background {
	background: rgba(250, 233, 241, 1);
}
.agent-loop-notion .block-color-red_background {
	background: rgba(252, 233, 231, 1);
}
.agent-loop-notion .select-value-color-default { background-color: rgba(42, 28, 0, 0.07); }
.agent-loop-notion .select-value-color-gray { background-color: rgba(28, 19, 1, 0.11); }
.agent-loop-notion .select-value-color-brown { background-color: rgba(127, 51, 0, 0.156); }
.agent-loop-notion .select-value-color-orange { background-color: rgba(196, 88, 0, 0.203); }
.agent-loop-notion .select-value-color-yellow { background-color: rgba(209, 156, 0, 0.282); }
.agent-loop-notion .select-value-color-green { background-color: rgba(0, 96, 38, 0.156); }
.agent-loop-notion .select-value-color-blue { background-color: rgba(0, 118, 217, 0.203); }
.agent-loop-notion .select-value-color-purple { background-color: rgba(92, 0, 163, 0.141); }
.agent-loop-notion .select-value-color-pink { background-color: rgba(183, 0, 78, 0.152); }
.agent-loop-notion .select-value-color-red { background-color: rgba(206, 24, 0, 0.164); }

.agent-loop-notion .checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.agent-loop-notion .checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.agent-loop-notion .checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}
	
</style><div class="agent-loop-notion"><article id="2dbd8e84-2ff9-802d-8e6d-da3c3ca35283" class="page sans"><header><h1 class="page-title" dir="auto">The Agent Loop Explained: How Modern LLM Apps Orchestrate Tools</h1><p class="page-description" dir="auto"></p></header><div class="page-body"><div style="display:contents" dir="auto"><p id="agent-loop-opening" class="">Agentic AI was the hottest label of 2025‚Äîand in Jan 2026 it‚Äôs still everywhere. But if the underlying model is still next-token prediction, what changed such that Cursor / Claude Code suddenly feel autonomous? Engineers keep tripping over the same three questions‚Äîme included: what is an agent (vs a chatbot or a deterministic workflow), what ‚Äúmagic‚Äù did LLMs add that makes this pattern work in production, and if we already have function calling, why do we need MCP at all? This post is my attempt to answer those questions end-to-end‚Äîby grounding everything in a concrete execution model you can actually implement and debug. By the end, we are going to implement and debug a real agent loop‚Äîtool calls, approvals, memory/state, multi-agent handoffs, and ‚Äúagentic‚Äù runtimes‚Äîby reading a run log end-to-end, using live examples from the OpenAI Agents SDK and the Claude Agent SDK. We‚Äôll start by defining the 4 primitives, then add state + MCP, cover scaling (routing + delegation), and finish with 3 runnable case studies.</p></div><div style="display:contents" dir="ltr"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="2dbd8e84-2ff9-800f-a753-d151283754d4"><div style="font-size:1.5em"><span class="icon">üí°</span></div><div style="width:100%"><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-809f-9005-c9cee04f5714" class=""><strong>TL;DR</strong></p></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-805c-ba0e-edfb608518e3" class="bulleted-list"><li style="list-style-type:disc">LLMs <strong>propose actions</strong>; runtimes <strong>execute</strong> them.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-8059-80bf-f0ba08c29224" class="bulleted-list"><li style="list-style-type:disc">‚ÄúAgent = while loop‚Äù is still the core mental model.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-80be-8f52-d0a3d8be93c0" class="bulleted-list"><li style="list-style-type:disc">API shift to <strong>Responses ‚ÄúItems‚Äù</strong>: actions become first-class context units.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-8018-ab17-fe1d0d3cf2e0" class="bulleted-list"><li style="list-style-type:disc"><strong>State</strong> is either manual, <code>previous_response_id</code>, or a <strong>Conversation</strong> object.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-80a8-ba6d-e853ca68040c" class="bulleted-list"><li style="list-style-type:disc">Tools come in 3 classes: <strong>custom functions</strong>, <strong>built-ins</strong>, <strong>remote MCP</strong>.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-80fe-b32d-e7a73b46ee89" class="bulleted-list"><li style="list-style-type:disc">MCP standardizes ‚Äúconnectors to real systems‚Äù + adds approvals/permissions.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-8033-8eff-c933e12abaa1" class="bulleted-list"><li style="list-style-type:disc">Scaling requires tool routing, tool search/catalog patterns, and multi-agent decomposition.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-8037-b076-e8913bf9d693" class="bulleted-list"><li style="list-style-type:disc">Coding agents work because they have <strong>verifiable signals</strong> (tests/builds/diffs).</li></ul></div></div></figure></div><div style="display:contents" dir="ltr"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="agent-loop-primitives"><div style="font-size:1.5em"><span class="icon">üß±</span></div><div style="width:100%"><div style="display:contents" dir="auto"><p class=""><strong>The 4 primitives (we‚Äôll reuse these labels throughout)</strong></p></div><div style="display:contents" dir="auto"><ul class="bulleted-list"><li style="list-style-type:disc"><strong>Model</strong>: proposes the next action (text or a tool call).</li></ul></div><div style="display:contents" dir="auto"><ul class="bulleted-list"><li style="list-style-type:disc"><strong>Runtime</strong>: executes tools, applies policy/approvals, and orchestrates the loop.</li></ul></div><div style="display:contents" dir="auto"><ul class="bulleted-list"><li style="list-style-type:disc"><strong>State</strong>: what gets fed into the <em>next</em> model call (history + tool results + memory).</li></ul></div><div style="display:contents" dir="auto"><ul class="bulleted-list"><li style="list-style-type:disc"><strong>Tools</strong>: capabilities the runtime can invoke on the model‚Äôs behalf.</li></ul></div></div></figure></div><div style="display:contents" dir="auto"><figure id="agent-loop-production-runtime-model" class="image"><a href="/Agent/The%20Agent%20Loop%20Explained%20How%20Modern%20LLM%20Apps%20Orche/The%20Agent%20Loop%20-%20Production%20Runtime%20Model.png"><img style="width:3024px" src="/Agent/The%20Agent%20Loop%20Explained%20How%20Modern%20LLM%20Apps%20Orche/The%20Agent%20Loop%20-%20Production%20Runtime%20Model.png" alt="Agent loop production runtime model"/></a><figcaption>Production runtime model</figcaption></figure></div><div style="display:contents" dir="ltr"><nav id="2dbd8e84-2ff9-8093-b8fe-c9590fdc2cff" class="block-color-gray table_of_contents"><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#s01-first-principles">1. First principles ‚Äî What the model is (and isn‚Äôt)</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#s02-agent-loop">2. The agent loop ‚Äî The smallest useful orchestration</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#s03-tool-calling-101">3. Tool calling 101 ‚Äî Actions as a data model</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#s04-conversation-state">4. Conversation state ‚Äî How history actually works</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s04-1-manual-history">4.1 Manual history list (classic)</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s04-2-previous-response-id">4.2 previous_response_id chaining</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s04-3-conversations-api">4.3 Conversations API ‚Äî Persistent conversation object</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s04-4-compaction">4.4 Compaction (advanced)</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#s05-mcp-in-practice">5. MCP in practice ‚Äî Why it exists and what it changes</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s05-1-mental-model">5.1 Mental model ‚Äî MCP as a shared tool host</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#s06-scaling-up">6. Scaling up ‚Äî Tool overload, routing, and tool search</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#s07-multi-agent-architectures">7. Multi-agent architectures ‚Äî Two types of delegation</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s07-1-router-handoff">7.1 Router/Triage ‚Üí Handoff (transfer control)</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s07-2-manager-worker">7.2 Manager/Worker (parallel decomposition)</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s07-3-agent-as-tool">7.3 Agent-as-tool / sub-agents (delegate, return control)</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#s08-case-study-1">8. Case study 1 ‚Äî Weather agent: ChatCompletions vs Responses</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s08-1-responses-api">8.1 Responses API</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s08-2-chatcompletions-api">8.2 ChatCompletions API</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#s09-case-study-2">9. Case study 2 ‚Äî Customer service agent: handoffs, state, and tracing</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s09-1-what-it-demonstrates">9.1 What it demonstrates</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s09-2-run-it-locally">9.2 Run it locally</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s09-3-what-youll-see">9.3 What you‚Äôll see (real transcript)</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s09-4-inspect-tracing">9.4 Inspect the run in Tracing</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#s10-case-study-3">10. Case study 3 ‚Äî Coding agent: terminal, verification, and sandboxing</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s10-1-code-review-agent">10.1 The code review agent</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s10-2-sandboxing-and-verification">10.2 Sandboxing and verification</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s10-3-run-examples">10.3 Run the examples (commands)</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#s11-appendix-1">11. Appendix 1 ‚Äî Two approaches to function calling (native vs prompted)</a></div><div class="table_of_contents-item table_of_contents-indent-1"><a class="table_of_contents-link" href="#s11-1-tool-schema-overload">11.1 Where it breaks first: tool schema overload</a></div><div class="table_of_contents-item table_of_contents-indent-0"><a class="table_of_contents-link" href="#s12-references">12. References</a></div></nav></div><div style="display:contents" dir="auto"><a id="2dbd8e84-2ff9-8038-ac25-ed00380a5419"></a><h2 id="s01-first-principles" class="">1. First principles ‚Äî What the model is (and isn‚Äôt)</h2></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-8085-9ed9-f187967c1e78" class="">Given that an LLM is fundamentally doing next-token prediction, ‚Äúfunction calling‚Äù is  just the model being trained to reliably emit a <strong>structured action format</strong> (a tool call) when the situation calls for it.</p></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-80e5-b587-e4ce96a5ed96" class="">Crucially, <strong>the LLM doesn‚Äôt execute functions</strong>. It only produces something equivalent to:</p></div><div style="display:contents" dir="auto"><blockquote id="2dbd8e84-2ff9-80e8-b91c-e7a875e09582" class="">‚ÄúI want to call tool X with arguments Y.‚Äù</blockquote></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-8020-a10c-e7fb994bdd0d" class="">Then a <strong>runtime</strong>‚Äîyour application code, or a platform runtime‚Äîdoes the real work: it parses that structured request, calls the underlying function/API, and <strong>appends the tool‚Äôs result back into the conversation</strong> so the model can continue.</p></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-806e-a2f8-f4b064805ae2" class="">That ‚Äúpropose vs. execute‚Äù boundary is the root of agent orchestration:</p></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-80e4-a6db-cf9c2c9ed26c" class="bulleted-list"><li style="list-style-type:disc">the model proposes actions,</li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-8009-b5a3-c76ce8087771" class="bulleted-list"><li style="list-style-type:disc">the runtime executes them,</li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-807d-bdbe-eca5a0a0db5b" class="bulleted-list"><li style="list-style-type:disc">the loop continues until the model decides it‚Äôs done.</li></ul></div><div style="display:contents" dir="ltr"><figure id="2dbd8e84-2ff9-80bd-82a8-f263d0bb5f80" class="image"><a href="/Agent/The%20Agent%20Loop%20Explained%20How%20Modern%20LLM%20Apps%20Orche/image.png"><img style="width:3024px" src="/Agent/The%20Agent%20Loop%20Explained%20How%20Modern%20LLM%20Apps%20Orche/image.png"/></a><figcaption><a href="#ref-1">[1]</a> OpenAI Tool Call</figcaption></figure></div><div style="display:contents" dir="auto"><a id="2dbd8e84-2ff9-801f-a33d-c0d527f8a1ce"></a><h2 id="s02-agent-loop" class="">2. The agent loop ‚Äî The smallest useful orchestration</h2></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-8069-8581-e14eb36ed596" class="">From the ground up, an agent is just a <strong>while loop</strong> wrapped around three things: a <strong>model</strong>, a <strong>tool</strong>, and a <strong>prompt/state</strong>. If you skim the OpenAI Agents SDK, the <code>Runner</code> in <a href="#ref-12">[12]</a> is basically an opinionated implementation of that loop: take the current state, ask the model what to do next, optionally run tools, then feed results back and repeat.</p></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-80c7-94c2-ead4c9c8389d" class="">
</p></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-804e-b551-d7871573a01f" class="">A clean way to think about it:</p></div><div style="display:contents" dir="auto"><blockquote id="2dbd8e84-2ff9-8070-b369-e93552a30bfe" class=""><strong>Agent loop =</strong> observe ‚Üí decide ‚Üí act ‚Üí observe (ReAct-style <a href="#ref-2">[2]</a> <a href="#ref-3">[3]</a>), until stop.</blockquote></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-8000-aa94-dddfbb877211" class="">I‚Äôll keep this abstract for now and make it concrete once we‚Äôve introduced tools + conversation state. The key is that ‚Äúagentic‚Äù behavior comes from the loop, not from any single model call.</p></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-8063-b8ef-f8b1bbf65dbc" class=""><strong>Stop conditions (production reality):</strong></p></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-8079-ac20-eb996493bf58" class="bulleted-list"><li style="list-style-type:disc">The model emits a final message (or a validated structured output)</li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-8040-b2f4-fa886d670145" class="bulleted-list"><li style="list-style-type:disc">Max turns / budget is reached</li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-809e-a7b9-d71a96e4e814" class="bulleted-list"><li style="list-style-type:disc">A tool error is fatal, or a policy/approval gate blocks an action</li></ul></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-80e6-8253-e4858dc95d01" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dbd8e84-2ff9-80aa-9ed7-e00644dbb2de"></a><h2 id="s03-tool-calling-101" class="">3. Tool calling 101 ‚Äî Actions as a data model</h2></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-8024-8b0d-f93f7d907db2" class="">Tool calling (as popularized by OpenAI‚Äôs function calling in 2023) is the simplest ‚Äúaction interface‚Äù for an LLM: instead of only writing text, the model can output a structured request to call a function‚Äîclassic tutorials use <code>get_weather</code>.<br/></p></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-8037-86ad-dc48502fc9d3" class="">A common misunderstanding (I had this too) is thinking ‚Äúthe model decides to call a tool‚Äù and ‚Äúthe tool gets called‚Äù are two separate ‚Äúsystems.‚Äù In practice, they‚Äôre one control loop: <strong>you send the model the available tools + the current history</strong>, and the model may directly output a structured tool request (with the exact tool name + args). Then the runtime executes it and appends the result back. </p></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-805f-b4a1-d346bf4f50c9" class="">
</p></div><div style="display:contents" dir="auto"><p class=""><strong>Where the API differences show up:</strong> the exact serialization details (Chat Completions vs Responses) are easiest to understand once you‚Äôve seen a full loop. We‚Äôll cover them in <a href="#s08-case-study-1">Case study 1</a>‚Äîfeel free to skim ahead and come back.</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8017-982f-e84b2a00f9d7" class="">Using Codex as an example: tool calling means the model emits a structured request (<code>function_call</code>), and the runtime executes it. In Codex, a single turn‚Äôs output can include a short preamble plus one or more <code>function_call</code> items‚Äîi.e., text and tool calls can appear together in the same response. The orchestration loop should therefore continue as long as any tool calls are present, and stop only when a turn produces no tool calls. <a href="#ref-16">[16]</a> <a href="#ref-17">[17]</a>
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-80ea-810e-dceba932408b"></a><h2 id="s04-conversation-state" class="">4. Conversation state ‚Äî How history actually works</h2></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80a3-b2b3-d8e0f1bd0924" class=""><strong>State</strong> is whatever you feed into the <em>next</em> model call. In practice, that‚Äôs a growing history list plus the tool results you append. There are three common ways to manage it in OpenAI APIs: (1) a manual history list, (2) <code>previous_response_id</code> chaining, and (3) a persistent Conversation object. When the window gets large, you compact.</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-8070-a55a-df2bbc437d20"></a><h3 id="s04-1-manual-history" class="">4.1 Manual history list (classic)</h3></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-806a-8f5f-f8befca54806" class="">You append <code>{user messages, assistant items/tool calls, tool outputs} </code></p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-80e4-88e6-d46d02275182"></a><h3 id="s04-2-previous-response-id" class="">4.2 <code>previous_response_id</code> chaining</h3></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8072-a758-ed9777fef3eb" class="">Responses lets you pass a prior response id to chain context</p></div><div style="display:contents" dir="auto"><pre id="2dcd8e84-2ff9-8082-810f-e88d9121ac6d" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">res1 = client.responses.create(
    model=&quot;gpt-5&quot;,
    input=&quot;What is the capital of France?&quot;,
    store=True
)

res2 = client.responses.create(
    model=&quot;gpt-5&quot;,
    input=&quot;And its population?&quot;,
    previous_response_id=res1.id,  # Automatic context!
    store=True
)</code></pre></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-8040-9c5d-cef252e5b7e7"></a><h3 id="s04-3-conversations-api" class="">4.3 Conversations API ‚Äî Persistent conversation object</h3></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8015-8f6b-dd6cb27a89ab" class="">OpenAI provides a <strong>Conversations API</strong> that manages history for you: a <strong>Conversation</strong> is a persistent container that stores the stream of Items (user messages, model outputs, tool calls, tool outputs) for a session.</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8022-b8fc-f810078c0289" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-8084-a035-d69ea00e2f2d"></a><h3 id="s04-4-compaction" class="">4.4 Compaction (advanced)</h3></div>
<div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80e1-bd64-cdcf66023666" class="">When history grows beyond context limits, the agent triggers compaction. This is the same mental model as Cursor/Claude Code ‚Äúsummaries,‚Äù but made explicit in the agent loop.</p></div>
<div style="display:contents" dir="auto"><p class="">Looking at OpenAI Codex source code <a href="#ref-16">[16]</a> here‚Äôs the flow:</p></div>
<div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-8078-82b0-fe3b15227b7b" class="bulleted-list"><li style="list-style-type:disc"><strong>1. Trigger Check</strong> ‚Äî Before each turn, check if <code>total_tokens &gt;= auto_compact_limit</code></li></ul></div>
<div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-80da-96ac-d3ea432e4765" class="bulleted-list"><li style="list-style-type:disc"><strong>2. Collect Everything</strong> ‚Äî Gather ALL history: messages, <code>function_call</code>, <code>function_call_output</code>, reasoning</li></ul></div>
<div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-8085-b40e-c82af825cc79" class="bulleted-list"><li style="list-style-type:disc"><strong>3. Extract User Messages</strong> ‚Äî From most recent backward, up to some number of tokens (truncating if needed)</li></ul></div>
<div style="display:contents" dir="auto"><ul id="agent-loop-compaction-step-4" class="bulleted-list"><li style="list-style-type:disc"><strong>4. Summarize</strong> ‚Äî Send entire history + Codex system prompt <a href="#ref-17">[17]</a> to the model</li></ul></div>
<div style="display:contents" dir="auto"><ul id="agent-loop-compaction-step-5" class="bulleted-list"><li style="list-style-type:disc"><strong>5. Rebuild &amp; Replace</strong> ‚Äî New history = <code>initial_context</code> + <code>summary_message</code> + <code>recent_user_messages</code></li></ul></div>
<div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8016-b777-ce90f2db5875" class=""><strong>Key insight:</strong> Keep system prompt and most recent user messages. Assistant responses, tool calls, and reasoning get distilled into a single summary. The agent loop continues with a compressed window.</p></div>
<div style="display:contents" dir="auto"><p class=""><strong>Concrete example</strong></p></div>
<div style="display:contents" dir="auto"><p class=""><strong>Before compaction (15 items):</strong></p></div>
<div style="display:contents" dir="auto"><pre id="agent-loop-compaction-before" class="code code-wrap"><code class="language-json" style="white-space:pre-wrap;word-break:break-all">[
  {&quot;type&quot;: &quot;message&quot;, &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;input_text&quot;, &quot;text&quot;: &quot;You are a coding assistant.&quot;}]},
  {&quot;type&quot;: &quot;message&quot;, &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;input_text&quot;, &quot;text&quot;: &quot;[Environment] cwd=/project&quot;}]},
  {&quot;type&quot;: &quot;message&quot;, &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;input_text&quot;, &quot;text&quot;: &quot;Create a FastAPI hello world&quot;}]},
  {&quot;type&quot;: &quot;reasoning&quot;, &quot;summary&quot;: [&quot;Need to create main.py&quot;, &quot;Will use FastAPI&quot;]},
  {&quot;type&quot;: &quot;function_call&quot;, &quot;call_id&quot;: &quot;call_001&quot;, &quot;name&quot;: &quot;shell&quot;, &quot;arguments&quot;: &quot;{\\&quot;command\\&quot;: [\\&quot;cat\\&quot;, \\\&quot;&gt;\\\&quot;, \\&quot;main.py\\&quot;]}&quot;},
  {&quot;type&quot;: &quot;function_call_output&quot;, &quot;call_id&quot;: &quot;call_001&quot;, &quot;output&quot;: &quot;{\\&quot;exit_code\\&quot;: 0}&quot;},
  {&quot;type&quot;: &quot;message&quot;, &quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;output_text&quot;, &quot;text&quot;: &quot;I&#x27;ve created main.py...&quot;}]},
  {&quot;type&quot;: &quot;message&quot;, &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;input_text&quot;, &quot;text&quot;: &quot;Add a /health endpoint&quot;}]},
  {&quot;type&quot;: &quot;function_call&quot;, &quot;call_id&quot;: &quot;call_002&quot;, &quot;name&quot;: &quot;apply_patch&quot;, &quot;arguments&quot;: &quot;{\\&quot;patch\\&quot;: \\&quot;...\\&quot;}&quot;},
  {&quot;type&quot;: &quot;function_call_output&quot;, &quot;call_id&quot;: &quot;call_002&quot;, &quot;output&quot;: &quot;{\\&quot;success\\&quot;: true}&quot;},
  {&quot;type&quot;: &quot;message&quot;, &quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;output_text&quot;, &quot;text&quot;: &quot;Added /health endpoint...&quot;}]},
  {&quot;type&quot;: &quot;message&quot;, &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;input_text&quot;, &quot;text&quot;: &quot;Run the tests&quot;}]},
  {&quot;type&quot;: &quot;function_call&quot;, &quot;call_id&quot;: &quot;call_003&quot;, &quot;name&quot;: &quot;shell&quot;, &quot;arguments&quot;: &quot;{\\&quot;command\\&quot;: [\\&quot;pytest\\&quot;]}&quot;},
  {&quot;type&quot;: &quot;function_call_output&quot;, &quot;call_id&quot;: &quot;call_003&quot;, &quot;output&quot;: &quot;{\\&quot;exit_code\\&quot;: 0, \\&quot;stdout\\&quot;: \\&quot;3 passed\\&quot;}&quot;},
  {&quot;type&quot;: &quot;message&quot;, &quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;output_text&quot;, &quot;text&quot;: &quot;All tests passed!&quot;}]}
]</code></pre></div>
<div style="display:contents" dir="auto"><p class=""><strong>After compaction (5 items):</strong></p></div>
<div style="display:contents" dir="auto"><pre id="agent-loop-compaction-after" class="code code-wrap"><code class="language-json" style="white-space:pre-wrap;word-break:break-all">[
  {&quot;type&quot;: &quot;message&quot;, &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;input_text&quot;, &quot;text&quot;: &quot;You are a coding assistant.&quot;}]},
  {&quot;type&quot;: &quot;message&quot;, &quot;role&quot;: &quot;system&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;input_text&quot;, &quot;text&quot;: &quot;[Environment] cwd=/project&quot;}]},
  {&quot;type&quot;: &quot;message&quot;, &quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;output_text&quot;, &quot;text&quot;: &quot;[Summary] Built FastAPI app with /health endpoint. All 3 tests passing.&quot;}]},
  {&quot;type&quot;: &quot;message&quot;, &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;input_text&quot;, &quot;text&quot;: &quot;[Previous]: Add a /health endpoint...&quot;}]},
  {&quot;type&quot;: &quot;message&quot;, &quot;role&quot;: &quot;user&quot;, &quot;content&quot;: [{&quot;type&quot;: &quot;input_text&quot;, &quot;text&quot;: &quot;[Previous]: Run the tests&quot;}]}
]</code></pre></div>
<div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-802a-a20b-ebc47214d95e" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-8052-822d-d4312b75fbb2"></a><h2 id="s05-mcp-in-practice" class="">5. MCP in practice ‚Äî Why it exists and what it changes</h2></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8052-9a62-e47016afc13c" class="">At this point, you already have tool calling‚Äîso why MCP?</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-807f-bdda-dc2caed3e35a" class="">
</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8048-8075-d0893ec27f2f" class=""><strong>Tool calling</strong> defines the <em>shape of an action</em> (‚Äúcall X with args Y‚Äù). <strong>MCP</strong> defines the <em>packaging of integrations</em>: how external systems expose a tool catalog + auth + permissions in a reusable, standard way. Think of MCP as a driver layer‚ÄîJDBC/ODBC, but for LLM tools.</p><div style="display:contents" dir="auto"><ul class="bulleted-list"><li style="list-style-type:disc"><strong>Before MCP:</strong> you hardcode tool schemas + auth per integration inside your app/runtime.</li></ul></div><div style="display:contents" dir="auto"><ul class="bulleted-list"><li style="list-style-type:disc"><strong>With MCP:</strong> you register a server, discover its tool catalog, and enforce permissions/approvals centrally‚Äîyour runtime plugs into integrations like plugins.</li></ul></div></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80c5-8abe-db459fa9fb2b" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-8062-a877-defb5ff20557"></a><h3 id="s05-1-mental-model" class="">5.1 Mental model ‚Äî MCP as a shared tool host</h3></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8066-8dd6-e267b49574f9" class="">Most MCP servers <em>do</em> look like ‚Äúwrappers around APIs‚Äù‚Äîand that‚Äôs not a knock, that‚Äôs the point. Instead of everyone writing their own Gmail wrapper / ClickHouse wrapper / Figma wrapper with different schemas and auth flows, an MCP server provides a <strong>standard discovery + invocation interface</strong> (‚Äúlist tools‚Äù, ‚Äúcall tool‚Äù, etc.), and the client (your agent runtime) can plug into it the same way across apps.</p></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-8004-be31-eb17d731c2b1" class="bulleted-list"><li style="list-style-type:disc">Example: Gmail MCP<div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-806c-a4ab-d4bc3989a63f" class="bulleted-list"><li style="list-style-type:circle">If you build an agent that researches a company and drafts an email to a hiring manager, a Gmail MCP server can expose a tool like ‚Äúcreate draft‚Äù that internally calls Gmail‚Äôs API. Someone else can reuse the same MCP server by configuring their own credentials, without rewriting the tool schema plumbing.</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-80a9-966d-e957b8bb479b" class="bulleted-list"><li style="list-style-type:disc"><strong>Example: ClickHouse (DB-class MCP)</strong><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-8067-80d5-ddc850840510" class="bulleted-list"><li style="list-style-type:circle">Database MCP servers are a ‚Äúresource access‚Äù pattern: once you configure credentials, the model can query a database through standardized tools (and depending on permissions, possibly write). This is exactly the ‚Äúconnect AI to where data lives‚Äù motivation MCP was designed for. </li></ul></div></li></ul></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8054-b0c8-da87bb0d3749" class="">
</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-809f-81ae-d0c1d633ce3f" class=""><strong>How it shows up in the OpenAI ecosystem <a href="#ref-5">[5]</a>:</strong> you register the MCP server in the <code>tools</code> list (server URL / connector + optional permissions), and the runtime can fetch the server‚Äôs tool catalog and call those tools as part of the same <strong>Responses Items</strong> action log we introduced earlier.</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-805f-841d-c2424fbe493b" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-809e-b5e7-d5ce4a4e2d49"></a><h2 id="s06-scaling-up" class="">6. Scaling up ‚Äî Tool overload, routing, and tool search</h2></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-806e-b76b-c9afa96e68e6" class="">Once the agent starts to work, the first thing that breaks is <em>not</em> ‚Äúthe loop‚Äù ‚Äî it‚Äôs <strong>tool overload</strong>.</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80eb-bd03-db9eaaa7c2d7" class="">
</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-806b-be1d-ea817807c31c" class="">If you give the model a small toolbelt (<code>get_weather</code>, <code>web_search</code>) and a tight scope, you can keep things close to a workflow: fewer tools, clearer routing, less ambiguity. But as you make an agent more ‚Äúgeneral‚Äù (coding agents are the canonical example), the tool count goes from <strong>5 ‚Üí 20 ‚Üí 200</strong> fast. At that point, ‚Äúdump all tool schemas into the prompt‚Äù becomes expensive and brittle: you burn context on definitions and <strong>tool selection quality degrades</strong>. Anthropic explicitly calls this out and motivates <strong>tool search / tool retrieval</strong>: load only the tool specs you need <em>when you need them</em>. </p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-804f-9b10-e2fd907c8653" class="">
</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80fc-89e4-ef1c18421aab" class="">My rule of thumb (opinion, but it holds up in practice):</p></div><div style="display:contents" dir="auto"><blockquote id="2dcd8e84-2ff9-80bc-8a2b-fdc938921559" class="">If the task needs many tools to do well, you‚Äôll eventually need routing.<div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8030-82ea-d354901c1125" class="">Routing can mean ‚Äúsmarter tool gating inside one agent,‚Äù or ‚Äúmultiple agents with smaller toolsets.‚Äù</p></div></blockquote></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80a6-911f-d81776a8a352" class="">Concretely, once you‚Äôre past ~10‚Äì20 tools, you usually end up with one (or a mix) of these mitigations:</p></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-8071-8afe-f594556b7523" class="bulleted-list"><li style="list-style-type:disc"><strong>Tool gating / allowlists (least privilege) <a href="#ref-6">[6]</a>.</strong> Don‚Äôt show every tool every time. Restrict tools by context (and for MCP, by server-side permissions / allowlists). Fewer tools ‚Üí less confusion ‚Üí lower latency.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-804b-ac36-eb3f9ab1c3ae" class="bulleted-list"><li style="list-style-type:disc"><strong>A routing/triage step <a href="#ref-8">[8]</a>.</strong> Add a cheap first step that classifies ‚Äúwhat bucket is this?‚Äù (billing vs refund vs technical) and then exposes only the relevant tool subset (or hands off to a specialist agent).</li></ul></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-8034-9924-ca29a5d8256a" class="bulleted-list"><li style="list-style-type:disc"><strong>Hierarchical decomposition.</strong> Treat ‚Äúbig capability‚Äù as a composition of smaller ones:<div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-8097-9c3e-e790569b8e8d" class="bulleted-list"><li style="list-style-type:circle"><em>agent-as-tool</em> (delegate subtasks but keep control), or</li></ul></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-8009-a80d-e9d3c024e8ae" class="bulleted-list"><li style="list-style-type:circle"><em>handoff</em> (transfer control). (We‚Äôll formalize these in the next section)</li></ul></div></li></ul></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-805f-8096-d93e0cfb39b0" class="bulleted-list"><li style="list-style-type:disc"><strong>Tool catalog retrieval (‚Äútool search‚Äù) <a href="#ref-6">[6]</a>.</strong> Keep a tool catalog outside the prompt, retrieve top-k relevant tool specs, and only load those. This is basically RAG, but for tools. </li></ul></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-80b5-a32a-d86ed3645bb3" class="bulleted-list"><li style="list-style-type:disc"><strong>Deterministic harness + non-deterministic decisions.</strong> If the agent will run long, wrap it in an orchestration layer that‚Äôs deterministic about execution/retries/state, while letting the LLM be non-deterministic about decisions. Temporal <a href="#ref-9">[9]</a> describes this split cleanly: deterministic <em>workflows</em> orchestrate; <em>activities</em> do the non-deterministic work (LLM calls, tool calls, APIs). </li></ul></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8046-b1de-c3d3468b7b65" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-800d-83ff-ccab50b7f680"></a><h2 id="s07-multi-agent-architectures" class="">7. Multi-agent architectures ‚Äî Two types of delegation</h2></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8021-bf51-d4064b43d54c" class="">Multi-agent systems are mostly a response to the scaling problem above: too many tools + too many competing behaviors in one context. If you compress the toolset and the role, the model routes better. </p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80d4-9b90-ed529670685f" class="">
</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80a8-964d-c5c288b78e75" class="">There are <strong>two distinct delegation moves</strong> people mix up:</p></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-80fe-a658-d05f620c4de8" class="bulleted-list"><li style="list-style-type:disc"><strong>Handoff = transfer control.</strong> After handoff, the other agent becomes the active controller for the conversation/next actions.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-80d7-b7e0-ec8b2b49d9a4" class="bulleted-list"><li style="list-style-type:disc"><strong>Agent-as-tool = delegate but keep control.</strong> he orchestrator calls a specialist agent like a tool, gets back an output, and continues driving.</li></ul></div><div style="display:contents" dir="ltr"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="2dcd8e84-2ff9-80eb-a808-c63ca1b8d0a0"><div style="font-size:1.5em"><span class="icon">üí°</span></div><div style="width:100%"><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-8080-b8d6-ca5e88a8d832" class="bulleted-list"><li style="list-style-type:disc"><em>Agent-as-tool</em> feels like calling a helper method ( ‚Äúinheritance‚Äù  function).</li></ul></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-80af-8453-f3bd248a54f4" class="bulleted-list"><li style="list-style-type:disc"><em>Handoff</em> is swapping the controller.</li></ul></div></div></figure></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-80e5-bb00-d8627a05baf2"></a><h3 id="s07-1-router-handoff" class="">7.1 Router/Triage ‚Üí Handoff (transfer control)</h3></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-801e-b157-fb0d4502804c" class="">This is the customer-support archetype: a triage agent decides ‚Äúbilling vs refund vs tech support,‚Äù then hands off to the specialist. OpenAI <a href="#ref-8">[8]</a> describe this as the way to keep prompts short and let each agent stay focused. </p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80cc-bde1-ff64d35d482a" class="">Why it works: each specialist agent gets a smaller toolset + cleaner context, and you stop contaminating one mega-context with every domain.</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-8049-ae91-fcd7287784ea"></a><h3 id="s07-2-manager-worker" class="">7.2 Manager/Worker (parallel decomposition)</h3></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-801e-a8ae-dfc42fa6e3ba" class="">This is ‚Äúdeep research‚Äù: one manager breaks a task into (mostly) non-overlapping subtasks, dispatches workers, then synthesizes. OpenAI‚Äôs <a href="#ref-8">[8]</a> practical guide presents manager/worker decomposition as a standard way to scale breadth-heavy tasks. </p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80e9-830d-ff7089ec6814" class="">When it wins: research + data gathering + multi-doc synthesis, where parallelism is real and you can validate sub-results independently.</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-80ed-86e9-d9292e6e5988"></a><h3 id="s07-3-agent-as-tool" class="">7.3 Agent-as-tool / sub-agents (delegate, return control)</h3></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8008-8e7e-e5998da42580" class=""><strong>This is the coding-agent pattern:</strong> the main agent keeps the overall thread (goal, constraints, repo state), but calls specialist sub-agents for focused work. A concrete example from Claude: <strong>code review as a sub-agent</strong>‚Äîyou want the reviewer to see the full edit history / diffs and reason deeply about correctness, while keeping the main code-generation loop‚Äôs context clean and on-track. Claude‚Äôs sub-agent docs <strong><a href="#ref-7">[7]</a></strong>  advocate this as a <strong>context hygiene + specialization</strong> strategy. On the OpenAI side, the same idea shows up as <strong>‚Äúagent-as-tool‚Äù</strong>: in the Agents SDK, you can expose an agent as a tool via <code>Agent.as_tool()</code> (see <code>Agent</code> in <strong><a href="#ref-11">[11]</a></strong>), so the orchestrator can delegate a subtask and then continue driving.</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80b2-a97c-c6ad43796991" class="">
</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80d3-8c1c-f68d2f77b279" class="">Why it‚Äôs powerful: you get specialization <strong>without losing the main controller‚Äôs plan/state</strong>. And you can bound sub-agent I/O (often via structured outputs), which keeps orchestration more deterministic even when the inner reasoning isn‚Äôt. </p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8027-b95d-f8116dfb6351" class="">
</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8075-a1f0-c2a54e474752" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-80ed-bf3b-c0cc1209199c"></a><h2 id="s08-case-study-1" class="">8. Case study 1 ‚Äî Weather agent: ChatCompletions vs Responses</h2></div><div style="display:contents" dir="auto"><p class=""><strong>Goal:</strong> implement a tiny weather agent loop twice‚Äîonce with Chat Completions, once with Responses‚Äîso you can see exactly what gets stored, what gets appended, and what gets sent back on the next turn.</p></div><div style="display:contents" dir="auto"><p class=""><strong>What to look for:</strong> where the tool call lives, where the tool output goes, and what the ‚Äústate‚Äù object looks like between turns.</p></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-8093-8774-d4bbd87e60ca" class=""><strong>What we‚Äôre comparing:</strong> the same one-tool agent loop, implemented twice. The loop is identical (model proposes ‚Üí runtime executes ‚Üí state grows); the difference is the <strong>action log serialization</strong>: <strong>Chat Completions</strong> nests tool calls inside assistant messages, while the <strong>Responses API</strong> emits typed <strong>Items</strong> in the output stream.</p></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-800c-8350-eb13359b939c" class="">
</p></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-80ec-ac92-f95152de70d5" class=""><strong>Chat Completions: actions live inside assistant messages</strong></p></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-8019-9b9d-d3c5b4a2aa56" class="bulleted-list"><li style="list-style-type:disc">Tool requests appear under <code>message.tool_calls</code></li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-8012-b3e9-f227613aa960" class="bulleted-list"><li style="list-style-type:disc">You append tool results as <code>{&quot;role&quot;:&quot;tool&quot;,&quot;tool_call_id&quot;:..., &quot;content&quot;:...}</code></li></ul></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-8003-af96-e1569cb598d8" class=""><strong>Responses: actions are first-class Items</strong></p></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-80e9-a907-cf527b874d52" class="bulleted-list"><li style="list-style-type:disc">Output is a list of typed Items: <code>message</code>, <code>reasoning</code>, <code>function_call</code>, <code>function_call_output</code>, etc.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-80d6-a9b3-e74e9ef593ba" class="bulleted-list"><li style="list-style-type:disc">This is the ‚Äúunifying trick‚Äù: <strong>context becomes a log of actions</strong>, not just chat text.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-8014-a0b4-cf8723fc791b" class="toggle"><li><details><summary>Response API vs Chat Completion API in Tool Call</summary><div style="display:contents" dir="ltr"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="2dbd8e84-2ff9-80e5-a802-e0c031574ff6"><div style="font-size:1.5em"><span class="icon">üí°</span></div><div style="width:100%"><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-807e-9884-f652b9897fd2" class="">For Responses, <code>name/description/parameters </code>are top-level on the tool definition (no nested <code>function</code> key). </p></div></div></figure></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-809c-a7ed-e1d1610986cc" class=""><strong>Response API vs Chat Completions API (tool call shape)</strong></p></div><div style="display:contents" dir="auto"><pre id="2dbd8e84-2ff9-802b-aeaf-c2b523749a1b" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all"># Chat Completions tool schema shape
{
  &quot;type&quot;: &quot;function&quot;,
  &quot;function&quot;: {
    &quot;name&quot;: &quot;get_weather&quot;,
    &quot;description&quot;: &quot;Determine weather in my location&quot;,
    &quot;strict&quot;: true,
    &quot;parameters&quot;: {
      &quot;type&quot;: &quot;object&quot;,
      &quot;properties&quot;: {&quot;location&quot;: {&quot;type&quot;: &quot;string&quot;}},
      &quot;additionalProperties&quot;: false,
      &quot;required&quot;: [&quot;location&quot;]
    }
  }
}</code></pre></div><div style="display:contents" dir="auto"><pre id="2dbd8e84-2ff9-804a-aecb-d3eacbd2891d" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all"># Responses tool schema shape
{
  &quot;type&quot;: &quot;function&quot;,
  &quot;name&quot;: &quot;get_weather&quot;,
  &quot;description&quot;: &quot;Determine weather in my location&quot;,
  &quot;parameters&quot;: {
    &quot;type&quot;: &quot;object&quot;,
    &quot;properties&quot;: {&quot;location&quot;: {&quot;type&quot;: &quot;string&quot;}},
    &quot;additionalProperties&quot;: false,
    &quot;required&quot;: [&quot;location&quot;]
  }
}
</code></pre></div><div style="display:contents" dir="ltr"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="2dbd8e84-2ff9-806d-9b82-e92658137665"><div style="font-size:1.5em"><span class="icon">üí°</span></div><div style="width:100%"><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-8013-87a7-c249c3ff7f5e" class="">Chat Completions returns tool calls nested under a <code>message</code>; Responses returns a distinct <code>function_call</code> Item (peer to <code>reasoning</code> / <code>message</code>).</p></div></div></figure></div><div style="display:contents" dir="auto"><pre id="2dbd8e84-2ff9-80e0-bb21-c3ae8344c973" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all"># Chat Completions response shape (simplified)
{
  &quot;choices&quot;: [{
    &quot;message&quot;: {
      &quot;role&quot;: &quot;assistant&quot;,
      &quot;content&quot;: None,
      &quot;tool_calls&quot;: [{
        &quot;id&quot;: &quot;call_xyz789&quot;,
        &quot;type&quot;: &quot;function&quot;,
        &quot;function&quot;: {
          &quot;name&quot;: &quot;get_weather&quot;,
          &quot;arguments&quot;: &quot;{\&quot;location\&quot;: \&quot;San Francisco\&quot;}&quot;
        }
      }]
    },
    &quot;finish_reason&quot;: &quot;tool_calls&quot;
  }]
}</code></pre></div><div style="display:contents" dir="auto"><pre id="2dbd8e84-2ff9-8051-a7c9-ca52d20ca9f3" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all"># Responses output items shape (simplified)
{
  &quot;output&quot;: [
    {
      &quot;id&quot;: &quot;rs_xxx&quot;,
      &quot;type&quot;: &quot;reasoning&quot;,
      &quot;content&quot;: [],
      &quot;summary&quot;: []
    },
    {
      &quot;id&quot;: &quot;fc_12345xyz&quot;,
      &quot;type&quot;: &quot;function_call&quot;,
      &quot;call_id&quot;: &quot;call_12345xyz&quot;,
      &quot;name&quot;: &quot;get_weather&quot;,
      &quot;arguments&quot;: &quot;{\&quot;location\&quot;:\&quot;Paris, France\&quot;}&quot;
    }
  ]
}</code></pre></div><div style="display:contents" dir="ltr"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="2dbd8e84-2ff9-8063-a077-f209b4e0ace9"><div style="font-size:1.5em"><span class="icon">üí°</span></div><div style="width:100%"><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-800a-8f9d-e8480fbc6951" class="">Tool outputs differ too: </p></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-8062-a058-d3c7a3e08fcd" class="bulleted-list"><li style="list-style-type:disc">Chat Completions uses role:&quot;tool&quot; + tool_call_id </li></ul></div><div style="display:contents" dir="auto"><ul id="2dbd8e84-2ff9-80cb-969f-e2cd46351b11" class="bulleted-list"><li style="list-style-type:disc">Responses uses type:&quot;function_call_output&quot; + call_id</li></ul></div></div></figure></div><div style="display:contents" dir="auto"><pre id="2dbd8e84-2ff9-8026-9c12-c13138acf84c" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all"># Chat Completions: append tool output
messages.append({
  &quot;role&quot;: &quot;tool&quot;,
  &quot;tool_call_id&quot;: tool_call.id,
  &quot;content&quot;: json.dumps(result)
})</code></pre></div><div style="display:contents" dir="auto"><pre id="2dbd8e84-2ff9-803a-afd0-c8f8fa6baaaf" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all"># Responses: append function_call_output item
input_list.append({
  &quot;type&quot;: &quot;function_call_output&quot;,
  &quot;call_id&quot;: item.call_id,
  &quot;output&quot;: json.dumps(result)
})</code></pre></div><div style="display:contents" dir="ltr"><figure class="block-color-gray_background callout" style="white-space:pre-wrap;display:flex" id="2dbd8e84-2ff9-80c1-94bf-d27333aeb769"><div style="font-size:1.5em"><span class="icon">üí°</span></div><div style="width:100%"><div style="display:contents" dir="auto"><h3 id="2dbd8e84-2ff9-80c5-9cc1-d106f3809228" class="">Built-in tools</h3></div><div style="display:contents" dir="auto"><p id="2dbd8e84-2ff9-8050-9780-c6199a3d0cd8" class=""><strong>Built-in tools</strong> (e.g., <code>web_search</code>) can be executed <em>platform-mediated</em> inside the Responses loop. <strong>Your custom function tools</strong> are still executed by <em>your runtime</em>; the model only proposes calls.</p></div></div></figure></div><div style="display:contents" dir="auto"><pre id="2dbd8e84-2ff9-80df-b67d-db47c62ba752" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">response = client.responses.create(
    model=&quot;gpt-5&quot;,
    input=&quot;Who is the current president of France?&quot;,
    tools=[{&quot;type&quot;: &quot;web_search&quot;}]  # Built-in tool!
)
# The API automatically executes web_search and returns final answer
# web_search, file_search, code_interpreter, computer_use, image_generation, Remote MCP servers</code></pre></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8054-b4b3-c9add113cdba" class="">Next, we‚Äôll run the same <code>get_weather</code> task end-to-end in both APIs, so you can see how these shapes turn into a real loop you can copy/paste.</p></div></details></li></ul></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-80c5-bce8-c681ce50e99d"></a><h3 id="s08-1-responses-api" class="">8.1 Responses API</h3></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80e1-b7b5-fcda7e2293c4" class="">The key of agent SDK design is <strong>structured I/O</strong>. Although ‚Äúatomic agents‚Äù sound composable (connect any agent‚Äôs output to another agent‚Äôs input), in practice it‚Äôs brittle because it often degenerates into <strong>mining structure out of chat text</strong>, which is unreliable. A more standard pattern is to keep a high-level workflow, where each node is an agent, and you enforce <strong>explicit structured boundaries</strong> between nodes. In the OpenAI Agents SDK this shows up naturally via Pydantic-style schemas / structured outputs <a href="#ref-10">[10]</a>. In the Python SDK, <code>response.output</code> is often surfaced as typed Item objects (Pydantic-style), so <code>item.type</code>, <code>item.name</code>, <code>item.call_id</code>, and <code>item.arguments</code> work directly‚Äîmaking the action log harder to accidentally treat as untyped text. <br/></p></div><div style="display:contents" dir="auto"><pre id="2dcd8e84-2ff9-808e-ba08-f99ee7960082" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">import json
from openai import OpenAI

client = OpenAI()  # uses OPENAI_API_KEY env var

prompt = &quot;What&#x27;s the weather in Paris today and should I bring an umbrella?&quot;

# Tool schema (Responses shape)
get_weather_tool = {
  &quot;type&quot;: &quot;function&quot;,
  &quot;name&quot;: &quot;get_weather&quot;,
  &quot;description&quot;: &quot;Get weather for a location + date&quot;,
  &quot;parameters&quot;: {
    &quot;type&quot;: &quot;object&quot;,
    &quot;properties&quot;: {
      &quot;location&quot;: {&quot;type&quot;: &quot;string&quot;},
      &quot;date&quot;: {&quot;type&quot;: &quot;string&quot;}
    },
    &quot;required&quot;: [&quot;location&quot;, &quot;date&quot;]
  }
}

def get_weather(location: str, date: str) -&gt; dict:
    return {&quot;location&quot;: location, &quot;date&quot;: date, &quot;temp_c&quot;: 15, &quot;condition&quot;: &quot;rain&quot;}

# 1) Ask model; output function_call Items
resp1 = client.responses.create(
  model=&quot;gpt-5&quot;,
  input=prompt,
  tools=[get_weather_tool],
)

# 2) Build next input as an action log: user input + all output items
inputs = [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}]
inputs += resp1.output  # typed Items

# 3) Execute function calls and append function_call_output Items
for item in resp1.output:
    if item.type == &quot;function_call&quot; and item.name == &quot;get_weather&quot;:
        args = json.loads(item.arguments)
        result = get_weather(**args)

        inputs.append({
          &quot;type&quot;: &quot;function_call_output&quot;,
          &quot;call_id&quot;: item.call_id,
          &quot;output&quot;: json.dumps(result),
        })
        
print(inputs)
&quot;&quot;&quot;
[
  {&#x27;role&#x27;: &#x27;user&#x27;,
   &#x27;content&#x27;: &quot;What&#x27;s the weather in Paris today and should I bring an umbrella?&quot;},
  ResponseReasoningItem(
    id=&#x27;rs_0a7b7198ca38866e00695749c0ece081909f9260133ddc1095&#x27;,
    summary=[],
    type=&#x27;reasoning&#x27;,
    content=None,
    encrypted_content=None,
    status=None
  ),
  ResponseFunctionToolCall(
    arguments=&#x27;{&quot;location&quot;:&quot;Paris&quot;,&quot;date&quot;:&quot;2026-01-02&quot;}&#x27;,
    call_id=&#x27;call_jztQX482ENTuKXkRLzAliRCF&#x27;,
    name=&#x27;get_weather&#x27;,
    type=&#x27;function_call&#x27;,
    id=&#x27;fc_0a7b7198ca38866e00695749d8cfdc8190b0b303d6f622b075&#x27;,
    status=&#x27;completed&#x27;
  ),
  {
    &#x27;type&#x27;: &#x27;function_call_output&#x27;,
    &#x27;call_id&#x27;: &#x27;call_jztQX482ENTuKXkRLzAliRCF&#x27;,
    &#x27;output&#x27;: &#x27;{&quot;location&quot;: &quot;Paris&quot;, &quot;date&quot;: &quot;2026-01-02&quot;, &quot;temp_c&quot;: 15, &quot;condition&quot;: &quot;rain&quot;}&#x27;
  }
]
&quot;&quot;&quot;
        
# 4) Ask model again with tool outputs appended
resp2 = client.responses.create(
  model=&quot;gpt-5&quot;,
  input=inputs,
  tools=[get_weather_tool],
)

print(resp2.output_text)
&quot;&quot;&quot;
It‚Äôs about 15¬∞C and rainy in Paris today. Yes‚Äîbring an umbrella (or a rain jacket).
&quot;&quot;&quot;</code></pre></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80ee-aae1-d8564f9ad8ef" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-80a3-a707-d8b29c293cb1"></a><h3 id="s08-2-chatcompletions-api" class="">8.2 ChatCompletions API</h3></div><div style="display:contents" dir="auto"><pre id="2dcd8e84-2ff9-8087-b34f-c2228b1ea7cf" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">import json
from openai import OpenAI

client = OpenAI()

# Tool schema (Chat Completions shape)
tools = [{
  &quot;type&quot;: &quot;function&quot;,
  &quot;function&quot;: {
    &quot;name&quot;: &quot;get_weather&quot;,
    &quot;description&quot;: &quot;Get weather for a location + date&quot;,
    &quot;parameters&quot;: {
      &quot;type&quot;: &quot;object&quot;,
      &quot;properties&quot;: {
        &quot;location&quot;: {&quot;type&quot;: &quot;string&quot;},
        &quot;date&quot;: {&quot;type&quot;: &quot;string&quot;}  # keep simple
      },
      &quot;required&quot;: [&quot;location&quot;, &quot;date&quot;]
    }
  }
}]

def get_weather(location: str, date: str) -&gt; dict:
    return {&quot;location&quot;: location, &quot;date&quot;: date, &quot;temp_c&quot;: 15, &quot;condition&quot;: &quot;rain&quot;}

messages = [
  {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What&#x27;s the weather in Paris today and should I bring an umbrella?&quot;}
]

# 1) Ask model; may return tool_calls
resp1 = client.chat.completions.create(
  model=&quot;gpt-4.1-mini&quot;,  
  messages=messages,
  tools=tools,
  tool_choice=&quot;auto&quot;
)

assistant_msg = resp1.choices[0].message
messages.append(assistant_msg)

# 2) Execute tool calls and append tool outputs
if assistant_msg.tool_calls:
    for tc in assistant_msg.tool_calls:
        args = json.loads(tc.function.arguments)
        result = get_weather(**args)

        messages.append({
          &quot;role&quot;: &quot;tool&quot;,
          &quot;tool_call_id&quot;: tc.id,
          &quot;content&quot;: json.dumps(result)
        })

# 3) Ask model again; now it can answer using tool output
resp2 = client.chat.completions.create(
  model=&quot;gpt-4.1-mini&quot;,
  messages=messages
)

print(messages)
&quot;&quot;&quot;
[
  {
    &#x27;role&#x27;: &#x27;user&#x27;,
    &#x27;content&#x27;: &quot;What&#x27;s the weather in Paris today and should I bring an umbrella?&quot;
  },
  ChatCompletionMessage(
    content=None,
    refusal=None,
    role=&#x27;assistant&#x27;,
    annotations=[],
    audio=None,
    function_call=None,
    tool_calls=[
      ChatCompletionMessageFunctionToolCall(
        id=&#x27;call_ImGa7bWcxYZVh9DLPe41vz4X&#x27;,
        function=Function(
          arguments=&#x27;{&quot;location&quot;:&quot;Paris&quot;,&quot;date&quot;:&quot;2024-04-27&quot;}&#x27;,
          name=&#x27;get_weather&#x27;
        ),
        type=&#x27;function&#x27;
      )
    ]
  ),
  {
    &#x27;role&#x27;: &#x27;tool&#x27;,
    &#x27;tool_call_id&#x27;: &#x27;call_ImGa7bWcxYZVh9DLPe41vz4X&#x27;,
    &#x27;content&#x27;: &#x27;{&quot;location&quot;: &quot;Paris&quot;, &quot;date&quot;: &quot;2024-04-27&quot;, &quot;temp_c&quot;: 15, &quot;condition&quot;: &quot;rain&quot;}&#x27;
  }
]
&quot;&quot;&quot;

print(resp2.choices[0].message.content)
&quot;&quot;&quot;
Today&#x27;s weather in Paris is rainy with a temperature around 15¬∞C. Yes, you should definitely bring an umbrella!
&quot;&quot;&quot;
</code></pre></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8059-ba1e-e871b20de59c" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-8039-b4d6-f800560f3e4c"></a><h2 id="s09-case-study-2" class="">9. Case study 2 ‚Äî Customer service agent: handoffs, state, and tracing</h2></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8081-aa9a-face78babbc2" class="">This demo is the <strong>customer-support archetype</strong> <a href="#ref-13">[13]</a> from <a href="#s07-multi-agent-architectures">Multi-agent architectures</a>: a lightweight <strong>Triage Agent</strong> routes the request, then <strong>hands off control</strong> to a specialist (<strong>Seat Booking Agent</strong>) that gathers missing info and calls a tool. It‚Äôs also a concrete example of <strong><a href="#s04-conversation-state">Conversation state</a></strong>: multiple turns share one thread, and the system‚Äôs behavior is visible as a run log.</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-80ce-ad30-df33b7177389"></a><h3 id="s09-1-what-it-demonstrates" class="">9.1 What it demonstrates</h3></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-80d5-a0f8-d9eed7cf62a0" class="bulleted-list"><li style="list-style-type:disc"><strong>Router/Triage ‚Üí Handoff:</strong> triage decides <em>who</em> should handle the request, then transfers control.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-8014-8414-ff2eaa5ad053" class="bulleted-list"><li style="list-style-type:disc"><strong>State across turns:</strong> the seat agent collects <code>CONF123</code> then <code>12A</code> over multiple user messages.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-80a7-af1e-d81621baa774" class="bulleted-list"><li style="list-style-type:disc"><strong>Tool execution boundary:</strong> the model proposes a tool call; the runtime executes it and returns the tool output.</li></ul></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-80f7-9c67-cc481bf16012" class="bulleted-list"><li style="list-style-type:disc"><strong>Production debugging:</strong> every step is inspectable in <strong>Tracing</strong>.</li></ul></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-80bd-895d-e9496c3535ea"></a><h3 id="s09-2-run-it-locally" class="">9.2 Run it locally</h3></div><div style="display:contents" dir="auto"><pre id="2dcd8e84-2ff9-80c5-8b97-c20f767f09da" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">git clone https://github.com/openai/openai-agents-python.git
cd openai-agents-python

# macOS: easiest install
brew install uv

# run the example (uv can manage the env for you)
uv run python examples/customer_service/main.py</code></pre></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-8054-827c-f6e84a746fd9"></a><h3 id="s09-3-what-youll-see" class="">9.3 What you‚Äôll see (real transcript)</h3></div><div style="display:contents" dir="auto"><pre id="2dcd8e84-2ff9-80c0-bbc5-c9283eabaa33" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">Enter your message: I want to change my seat

Triage Agent: Skipping item: HandoffCallItem
Handed off from Triage Agent to Seat Booking Agent
Seat Booking Agent: I can help you with changing your seat. To get started, could you please provide your flight confirmation number?

Enter your message: CONF123
Seat Booking Agent: Thank you! What seat number would you like to change to?

Enter your message: 12A
Seat Booking Agent: Calling a tool
Seat Booking Agent: Tool call output: Updated seat to 12A for confirmation number CONF123
Seat Booking Agent: Your seat has been changed to 12A. If you need any further assistance or have additional requests, please let me know!

Enter your message: no
Seat Booking Agent: Great! Your seat change is all set. Have a wonderful flight!
</code></pre></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-803e-99ff-caad543fe0b3"></a><h3 id="s09-4-inspect-tracing" class="">9.4 Inspect the run in Tracing</h3></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80bb-871d-c038ae8ff313" class="">Tracing is enabled by default for this example and groups under a conversation id, so you can review <strong>handoffs, tool calls, and timing</strong> end-to-end in the dashboard: <a href="https://platform.openai.com/traces">platform.openai.com/traces</a></p></div><div style="display:contents" dir="ltr"><figure id="2dcd8e84-2ff9-803f-a550-e5409f774f9e" class="image"><a href="/Agent/The%20Agent%20Loop%20Explained%20How%20Modern%20LLM%20Apps%20Orche/image%201.png"><img style="width:3718px" src="/Agent/The%20Agent%20Loop%20Explained%20How%20Modern%20LLM%20Apps%20Orche/image%201.png"/></a><figcaption>OpenAl Traces dashboard showing customer service runs with handoffs/tool counts</figcaption></figure></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80cb-af29-febe0d5868c4" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-8001-b9a0-d60a45913079"></a><h2 id="s10-case-study-3" class="">10. Case study 3 ‚Äî Coding agent: terminal, verification, and sandboxing</h2></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80b6-9fc6-d329266668f2" class="">
</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80a9-9ed0-cbc14acdeca3" class="">Coding agents are the ‚Äúhigh-agency‚Äù example because they have <strong>verifiable signals</strong>. A good coding agent (Cursor / Claude Code today) can <strong>navigate a repo</strong>, <strong>edit files</strong>, <strong>run commands/tests</strong>, inspect diffs, and iterate until verification passes.</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80d4-82c2-ec67e45f60f1" class="">
</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8021-9119-fba2dd3963f0" class="">The architecture is still prompt + model + tools. The step-change is that the tool set includes a <strong>universal actuator (shell + filesystem)</strong>, so the agent can <strong>fetch context on demand</strong> and <strong>produce verifiable evidence</strong> by running commands.</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80ad-b3b9-e1b2dec792d1" class="">
</p></div><div style="display:contents" dir="auto"><blockquote id="2dcd8e84-2ff9-802b-a3e7-c924cb56a5b2" class="">The step-change from ‚ÄúIDE copilot‚Äù to ‚Äúagentic coding‚Äù happens when the model can <strong>pull context by itself</strong> (search/locate files) and <strong>prove correctness</strong> (run tests/builds).</blockquote></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8047-9bab-e9b59429d108" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-80bb-a5b2-e7f942946964"></a><h3 id="s10-1-code-review-agent" class="">10.1 The code review agent</h3></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80f2-89d5-fa79e0ab2a2a" class="">We‚Äôll use the Claude Agent SDK example (<code>examples/agents.py</code>) <a href="#ref-14">[14]</a>, which defines <strong>specialist sub-agents</strong> with tight tool allowlists:</p></div><div style="display:contents" dir="auto"><ul id="2dcd8e84-2ff9-80a1-bdb9-c4e37be091dc" class="bulleted-list"><li style="list-style-type:disc"><code>code-reviewer</code>: tools <code>[&quot;Read&quot;, &quot;Grep&quot;]</code></li></ul></div><div style="display:contents" dir="auto"><pre id="2dcd8e84-2ff9-8077-a09b-c872ee9097c0" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">options = ClaudeAgentOptions(
    agents={
        &quot;code-reviewer&quot;: AgentDefinition(
            description=&quot;Reviews code for best practices and potential issues&quot;,
            prompt=(
                &quot;You are a code reviewer. Analyze code for bugs, performance issues, &quot;
                &quot;security vulnerabilities, and adherence to best practices. &quot;
                &quot;Provide constructive feedback.&quot;
            ),
            tools=[&quot;Read&quot;, &quot;Grep&quot;],
            model=&quot;sonnet&quot;,
        ),
    },
)

async for message in query(
    prompt=&quot;Use the code-reviewer agent to review the code in src/claude_agent_sdk/types.py&quot;,
    options=options,
):
    ...</code></pre></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-800a-99dc-c16b137f4d11" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-80b3-9ef4-f59fb17c8d8d"></a><h3 id="s10-2-sandboxing-and-verification" class="">10.2 Sandboxing and verification</h3></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-800a-bef6-fa1147e3dc8c" class="">Once an agent can <strong>Write</strong> and <strong>Bash</strong>, production deployments need two distinct layers:<br/></p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-806a-9638-eb3cc283474b" class=""><strong>1. Safety gates (policy + sandboxing)</strong><br/>A deterministic layer that enforces what&#x27;s allowed <em>before</em> execution: path redirection, command allowlists, deny rules. This sits between the model&#x27;s proposed action and actual execution.</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-808e-b105-ca4081cf4818" class=""><strong>2. Verification (agent-driven)</strong></p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-807f-acb4-e692fbdf9843" class="">The agent uses terminal tools to check its own work: run tests, inspect outputs, compare diffs. This feedback loop lets the agent iterate toward correctness rather than emit code and stop.</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-806a-aa1f-e53ac05d8d71" class="">In <code>examples/tool_permission_callback.py</code> <a href="#ref-15">[15]</a>, the run log shows both layers in action:</p></div><div style="display:contents" dir="ltr"><table id="2dcd8e84-2ff9-805b-89a6-f396f7fbfeb5" class="simple-table"><thead class="simple-table-header"><div style="display:contents" dir="ltr"><tr id="2dcd8e84-2ff9-8067-b26b-f40fc2c77a30"><th id=":NG|" class="simple-table-header-color simple-table-header">Step</th><th id="RHrF" class="simple-table-header-color simple-table-header">Layer</th><th id="&gt;fLR" class="simple-table-header-color simple-table-header">What happened</th></tr></div></thead><tbody><div style="display:contents" dir="ltr"><tr id="2dcd8e84-2ff9-80cc-a6fb-fc33189ed78d"><td id=":NG|" class="">Agent attempts <code>Write</code> to <code>/Users/user_name/hello.py</code></td><td id="RHrF" class="">Safety gate</td><td id="&gt;fLR" class="">Redirected ‚Üí <code>./safe_output/hello.py</code></td></tr></div><div style="display:contents" dir="ltr"><tr id="2dcd8e84-2ff9-800d-9baa-c10cc4a9c753"><td id=":NG|" class="">Agent runs <code>python3 hello.py</code></td><td id="RHrF" class="">Safety gate</td><td id="&gt;fLR" class="">Allowed (matches bash allowlist)</td></tr></div><div style="display:contents" dir="ltr"><tr id="2dcd8e84-2ff9-80c3-a720-e36ae0a57a0e"><td id=":NG|" class="">Agent re-runs from safe path, checks output</td><td id="RHrF" class="">Verification</td><td id="&gt;fLR" class="">Agent confirms script works</td></tr></div></tbody></table></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80c6-b65e-efec79fb4462" class="">In practice, you want both <strong>Deterministic policy</strong> which controls what <em>can</em> happen and <strong>agent-driven verification</strong> that confirms what <em>did</em> happen worked</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80de-80c3-c65747e3b122" class="">
</p></div><div style="display:contents" dir="auto"><pre id="2dcd8e84-2ff9-808c-8d34-f65c1cc99f57" class="code code-wrap"><code class="language-Python" style="white-space:pre-wrap;word-break:break-all">üí¨ Claude: Now let me create the hello world Python script:

üîß Tool Permission Request: Write
   Input: {
  &quot;file_path&quot;: &quot;/Users/user_name/hello.py&quot;,
  &quot;content&quot;: &quot;#!/usr/bin/env python3\n\nprint(\&quot;Hello, World!\&quot;)\n&quot;
}
   ‚ö†Ô∏è  Redirecting write from /Users/user_name/hello.py to ./safe_output/hello.py

üí¨ Claude: Now let me run the script to test it:

üîß Tool Permission Request: Bash
   Input: {
  &quot;command&quot;: &quot;python3 hello.py&quot;,
  &quot;description&quot;: &quot;Run the hello world script&quot;
}
   ‚úÖ Allowing bash command: python3 hello.py

üí¨ Claude: Let me check where the file was actually created and run it from there:

üîß Tool Permission Request: Bash
   Input: {
  &quot;command&quot;: &quot;python3 ./safe_output/hello.py&quot;,
  &quot;description&quot;: &quot;Run hello.py from safe_output&quot;
}
   ‚úÖ Allowing bash command: python3 ./safe_output/hello.py

üí¨ Claude: Perfect! All tasks completed successfully:</code></pre></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-801d-86dd-c15abfc6a298" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-80ca-8d7a-f63aaa904aeb"></a><h3 id="s10-3-run-examples" class="">10.3 Run the examples (commands)</h3></div><div style="display:contents" dir="auto"><pre id="2dcd8e84-2ff9-8096-b96f-d22ef2a1234f" class="code code-wrap"><code class="language-Bash" style="white-space:pre-wrap;word-break:break-all">git clone https://github.com/anthropic/claude-agent-sdk-python.git
cd claude-agent-sdk-python

python3 -m venv .venv
source .venv/bin/activate

python -m pip install -U pip
python -m pip install -e &quot;.[dev]&quot;

python -c &quot;import claude_agent_sdk; print(&#x27;claude-agent-sdk&#x27;, claude_agent_sdk.__version__)&quot;

# Ensure the Claude Code CLI exists (download step may require network + auth)
command -v claude &gt;/dev/null || python scripts/download_cli.py

# Demos
python examples/quick_start.py
python examples/tool_permission_callback.py

# Sub-agent examples (forces imports from ./src)
PYTHONPATH=&quot;$(pwd)/src&quot; ./.venv/bin/python examples/agents.py</code></pre></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8075-b23f-e32e5d86307b" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-8026-9077-f37ac0abb8bf"></a><h2 id="s11-appendix-1" class="">11. Appendix 1 ‚Äî Two approaches to function calling (native vs prompted)</h2></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-807a-a1d1-cc217911dfd7" class="">The <strong>two approaches to function calling</strong> look like this:</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8003-bdb5-ccbb5c22a7e5" class=""><strong>(1) Native tool calling.</strong> Models like <strong>GPT-4, Claude 3.x, and Gemini</strong> are generally fine-tuned / RLHF‚Äôd to emit tool calls in the API‚Äôs <strong>structured field</strong> (i.e., the model directly returns a tool call object with a tool name + JSON args).</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80ae-825a-db0790bcc68c" class=""><strong>(2) Prompted tool calling.</strong> For some models that aren‚Äôt reliably trained on tool-call trajectories (e.g., <strong>DeepSeek R1</strong>), you can still make tools work‚Äîbut you often need to <strong>instruct the model to emit a tool-call DSL</strong> (XML/JSON-like), and then your runtime parses and executes it. Think something like:</p></div><div style="display:contents" dir="auto"><pre id="2dcd8e84-2ff9-8085-9703-e25b0a656671" class="code code-wrap"><code class="language-Plain Text" style="white-space:pre-wrap;word-break:break-all">&lt;read_file&gt;
  &lt;path&gt;src/main.js&lt;/path&gt;
&lt;/read_file&gt;</code></pre></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-807d-b525-f55fe31c8773" class="">Either way, the key invariant from <a href="#s01-first-principles">First principles</a> still holds: <strong>the runtime executes tools and feeds results back</strong>‚Äîthe model is only producing a structured request.</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-809c-a726-c0e5fe52df8a" class="">
</p></div><div style="display:contents" dir="auto"><a id="2dcd8e84-2ff9-8019-87d7-ea3160fab44d"></a><h3 id="s11-1-tool-schema-overload" class="">11.1 Where it breaks first: tool schema overload</h3></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-8017-b867-ce7eed99d758" class="">If you choose the ‚Äúprompted tool calling‚Äù route, you typically end up stuffing <em>all</em> tool definitions (names, parameters, descriptions) into the system prompt so the model can produce valid calls. </p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80a0-818e-eea62700927d" class="">This is the <strong>context overload</strong> issue people hit in early versions of coding agents (Claude Code is a good example): once you have 20+ tools (or worse, hundreds), you burn tokens on tool schemas, and tool selection starts to degrade.</p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-80ce-91e7-d1b3371ca3ec" class="">So how do we deal with it? That‚Äôs exactly what we‚Äôll answer in <a href="#s06-scaling-up">section 6 </a> (tool overload + routing + ‚Äútool search‚Äù / tool catalog retrieval).</p></div><div style="display:contents" dir="auto"><a id="2dbd8e84-2ff9-801f-9c49-eb4983ee999a"></a><h2 id="s12-references" class="">12. References</h2></div><div style="display:contents" dir="auto"><p id="ref-1" class="">[1] OpenAI Tool Calling Guide: <a href="https://platform.openai.com/docs/guides/function-calling">https://platform.openai.com/docs/guides/function-calling</a></p></div><div style="display:contents" dir="auto"><p id="ref-2" class="">[2] ReAct Paper: <a href="https://arxiv.org/pdf/2210.03629">https://arxiv.org/pdf/2210.03629</a></p></div><div style="display:contents" dir="auto"><p id="ref-3" class="">[3] LlamaIndex ReAct Agent: <a href="https://developers.llamaindex.ai/python/examples/agent/react_agent/?utm_source=chatgpt.com">https://developers.llamaindex.ai/python/examples/agent/react_agent/?utm_source=chatgpt.com</a></p></div><div style="display:contents" dir="auto"><p id="ref-4" class="">[4] OpenAI Conversation State Guide: <a href="https://platform.openai.com/docs/guides/conversation-state">https://platform.openai.com/docs/guides/conversation-state</a></p></div><div style="display:contents" dir="auto"><p id="ref-5" class="">[5] OpenAI MCP Tool Guide: <a href="https://cookbook.openai.com/examples/mcp/mcp_tool_guide">https://cookbook.openai.com/examples/mcp/mcp_tool_guide</a></p></div><div style="display:contents" dir="auto"><p id="ref-6" class="">[6] Anthropic Advanced Tool Use: <a href="https://www.anthropic.com/engineering/advanced-tool-use">https://www.anthropic.com/engineering/advanced-tool-use</a></p></div><div style="display:contents" dir="auto"><p id="ref-7" class="">[7] Claude Sub-Agents Docs: <a href="https://code.claude.com/docs/en/sub-agents">https://code.claude.com/docs/en/sub-agents</a></p></div><div style="display:contents" dir="auto"><p id="ref-8" class="">[8] OpenAI Agents Practical Guide: <a href="https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf">https://cdn.openai.com/business-guides-and-resources/a-practical-guide-to-building-agents.pdf</a></p></div><div style="display:contents" dir="auto"><p id="ref-9" class="">[9] Temporal Dynamic AI Agents: <a href="https://temporal.io/blog/of-course-you-can-build-dynamic-ai-agents-with-temporal?utm_source=chatgpt.com">https://temporal.io/blog/of-course-you-can-build-dynamic-ai-agents-with-temporal?utm_source=chatgpt.com</a></p></div><div style="display:contents" dir="auto"><p id="ref-10" class="">[10] OpenAI Structured Outputs Guide: <a href="https://platform.openai.com/docs/guides/structured-outputs?example=moderation">https://platform.openai.com/docs/guides/structured-outputs?example=moderation</a></p></div><div style="display:contents" dir="auto"><p id="ref-11" class="">[11] OpenAI Agents SDK Agent: <a href="https://github.com/openai/openai-agents-python/blob/main/src/agents/agent.py">https://github.com/openai/openai-agents-python/blob/main/src/agents/agent.py</a></p></div><div style="display:contents" dir="auto"><p id="ref-12" class="">[12] OpenAI Agents SDK Runner: <a href="https://github.com/openai/openai-agents-python/blob/main/src/agents/run.py">https://github.com/openai/openai-agents-python/blob/main/src/agents/run.py</a></p></div><div style="display:contents" dir="auto"><p id="ref-13" class="">[13] OpenAI Agents SDK Customer Service: <a href="https://github.com/openai/openai-agents-python/blob/main/examples/customer_service/main.py">https://github.com/openai/openai-agents-python/blob/main/examples/customer_service/main.py</a></p></div><div style="display:contents" dir="auto"><p id="ref-14" class="">[14] Claude Agent SDK Examples: <a href="https://github.com/anthropics/claude-agent-sdk-python/blob/main/examples/agents.py">https://github.com/anthropics/claude-agent-sdk-python/blob/main/examples/agents.py</a></p></div><div style="display:contents" dir="auto"><p id="ref-15" class="">[15] Claude Tool Permission Callback: <a href="https://github.com/anthropics/claude-agent-sdk-python/blob/main/examples/tool_permission_callback.py">https://github.com/anthropics/claude-agent-sdk-python/blob/main/examples/tool_permission_callback.py</a></p></div><div style="display:contents" dir="auto"><p id="ref-16" class="">[16] OpenAI Codex Tool Call Loop: <a href="https://github.com/openai/codex/blob/cf515142b0cb8024a82314686a34d43f03b1ea4d/codex-rs/core/src/codex.rs#L2417C1-L2446C14">https://github.com/openai/codex/blob/cf515142b0cb8024a82314686a34d43f03b1ea4d/codex-rs/core/src/codex.rs#L2417C1-L2446C14</a></p></div><div style="display:contents" dir="auto"><p id="ref-17" class="">[17] OpenAI Codex System Prompt: <a href="https://github.com/openai/codex/blob/cf515142b0cb8024a82314686a34d43f03b1ea4d/codex-rs/core/prompt.md">https://github.com/openai/codex/blob/cf515142b0cb8024a82314686a34d43f03b1ea4d/codex-rs/core/prompt.md</a></p></div><div style="display:contents" dir="auto"><p id="2dcd8e84-2ff9-801c-8923-e6ae29151968" class="">
</p></div></div></article><span class="sans" style="font-size:14px;padding-top:2em"></span>


<!-- Prism core + theme (included once) -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" integrity="sha512-tN7Ec6zAFaVSG3TpNAKtk4DOHNpSwKHxxrsiw4GHKESGPs5njn/0sMCUMl2svV4wo4BK/rCP7juYz+zx+l6oeQ==" crossorigin="anonymous" referrerPolicy="no-referrer"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js" integrity="sha512-7Z9J3l1+EYfeaPKcGXu3MS/7T+w19WtKQY/n+xzmw4hZhJ9tyYmcUS+4QqAlzhicE5LAfMQSF3iFTK9bQdTxXg==" crossorigin="anonymous" referrerPolicy="no-referrer"></script>
<!-- Prism syntax highlighting (autoload languages like Python/Bash) -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js" crossorigin="anonymous" referrerPolicy="no-referrer"></script>

<script src="/assets/js/agent-loop.js?v={{ site.time | date: '%s' }}"></script>

</div>
